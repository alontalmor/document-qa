{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:36.992926Z",
     "start_time": "2018-10-07T09:34:36.961699Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 140)\n",
    "pd.set_option('display.width', 2000)\n",
    "import sys,os\n",
    "from IPython.core.debugger import Tracer\n",
    "from IPython.core.debugger import BdbQuit_excepthook\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import nltk\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "from pandas import ExcelWriter\n",
    "from ast import literal_eval\n",
    "import hashlib\n",
    "import unicodedata\n",
    "import subprocess\n",
    "import datetime\n",
    "m = hashlib.md5()\n",
    "from nltk.metrics import *\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import zipfile\n",
    "import pymongo\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.015568Z",
     "start_time": "2018-10-07T09:34:36.994558Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "EXP_NAME = 'ComQA-G'\n",
    "EVAL_SET = 'train' # train, dev, test , which split to run on \n",
    "WRITE_EVIDENCE = 0 # should we write the evidence to file\n",
    "SEARCHRESULTS_FROM_FILES = 1\n",
    "FILES_PER_QUESTION = 20 # how many evidence files to build per question\n",
    "LIMIT_TRAIN_SIZE = -1\n",
    "PRODUCE_ONLY_SAMPLE = 0\n",
    "RUN_EXPERIMENTS = 0\n",
    "\n",
    "# DataSets\n",
    "USE_WIKITABLEQ = 0\n",
    "USE_MSMARCO = 0\n",
    "USE_SEARCHQA = 0\n",
    "USE_TRIVIAQA = 0\n",
    "USE_SQUAD = 0\n",
    "USE_COMPWEBQ = 0\n",
    "USE_COMQA = 1\n",
    "\n",
    "# Dataset Specific \n",
    "# Squad\n",
    "USE_TRIVIAQA_ORG_CONTEXT = 0\n",
    "USE_SQUAD_ORG_CONTEXT = 0\n",
    "USE_MSMARCO_ORG_CONTEXT = 0\n",
    "# ComplexWebQuestions\n",
    "ADD_SPLITS_TO_TRAIN = 1\n",
    "\n",
    "# GENERAL\n",
    "#PRODUCE_ONLY_SAMPLE = True\n",
    "EVIDENCE_DIR = '/Users/alontalmor/Documents/dev/datasets/triviaqa/triviaqa-rc/'\n",
    "\n",
    "# Tests\n",
    "CALC_ANSWER_IN_GOOGLE_PERC = 0\n",
    "GOOGLE_FILTERED_FILES = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:29:54.834220Z",
     "start_time": "2018-05-15T07:29:54.713840Z"
    }
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.020018Z",
     "start_time": "2018-10-07T09:34:37.017547Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "Data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIKITABLEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.032435Z",
     "start_time": "2018-10-07T09:34:37.021648Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_wikitableq(dirname,filename):\n",
    "    mturk_full_track = pd.read_csv(dirname + 'mturk_full_track.csv', encoding = \"utf-8\",index_col=0).reset_index()\n",
    "         \n",
    "    if filename == 'dev':\n",
    "        return mturk_full_track[['qid','rephrased_question','answers']].sample(frac=0.1,random_state=1)\n",
    "    else:\n",
    "        return mturk_full_track[['qid','rephrased_question','answers']].sample(frac=0.9,random_state=1)\n",
    "    \n",
    "if USE_WIKITABLEQ and EVAL_SET == 'dev':\n",
    "    \n",
    "    # empty search results\n",
    "    #Data['ComQA']['SearchResults']  = Data['ComQA']['SearchResults'].astype(object)\n",
    "    #Data['ComQA']['SearchResults'] = np.empty((len(Data['ComQA']), 0)).tolist()\n",
    "     Data['WikiTableQ'] = load_wikitableq('/Users/alontalmor/Dropbox/Backup/QAResearch/ipython/MTurk_TableQA_Rephrasing/','dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T13:06:33.020358Z",
     "start_time": "2018-10-04T13:06:33.001273Z"
    }
   },
   "source": [
    "### ComQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.051526Z",
     "start_time": "2018-10-07T09:34:37.034047Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_comqa(dirname,filename):\n",
    "    with open(dirname + 'comqa_' + filename + '.json') as myfile:\n",
    "        raw_questions = json.load(myfile)\n",
    "        \n",
    "    all_questions = []\n",
    "    for cluster in raw_questions:\n",
    "        for question in cluster['questions']:\n",
    "            # building ID\n",
    "            m = hashlib.md5()\n",
    "            m.update(question.encode())\n",
    "            ID = m.hexdigest()\n",
    "            all_questions.append({'question':question,'answers':cluster['answers'],'ID':ID})\n",
    "        \n",
    "    return pd.DataFrame(all_questions)\n",
    "    \n",
    "if USE_COMQA and EVAL_SET == 'dev':\n",
    "    \n",
    "    # empty search results\n",
    "    #Data['ComQA']['SearchResults']  = Data['ComQA']['SearchResults'].astype(object)\n",
    "    #Data['ComQA']['SearchResults'] = np.empty((len(Data['ComQA']), 0)).tolist()\n",
    "     Data['ComQA'] = load_comqa('/Users/alontalmor/Documents/dev/datasets/ComQA/','dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SearchQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.055306Z",
     "start_time": "2018-10-07T09:34:37.052967Z"
    }
   },
   "outputs": [],
   "source": [
    "#ilename = '/Users/alontalmor/Documents/dev/datasets/SearchQA/data_json/000488-5243_jeopardy_beginningend_600.json'\n",
    "#with open(filename,'r') as f:\n",
    "#    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.059441Z",
     "start_time": "2018-10-07T09:34:37.057125Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(data)['question'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.063298Z",
     "start_time": "2018-10-07T09:34:37.061152Z"
    }
   },
   "outputs": [],
   "source": [
    "#data['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.076146Z",
     "start_time": "2018-10-07T09:34:37.065095Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_SEARCHQA:\n",
    "    def load_searchqa(dirname,filename):\n",
    "        print(os.path.join(dirname,filename +'.zip'))\n",
    "        with zipfile.ZipFile(os.path.join(dirname,filename +'.zip'),'r') as myzip:\n",
    "            with myzip.open(filename) as myfile:\n",
    "                searchqa_json = json.load(myfile)\n",
    "        #with gzip.open(os.path.join(dirname,filename +'.zip'),'rb') as myzip:\n",
    "        #    searchqa_json=pd.DataFrame(json.loads(myzip.read()))\n",
    "\n",
    "        return searchqa_json\n",
    "    if USE_SEARCHQA and EVAL_SET == 'dev':\n",
    "         Data['searchqa'] = load_searchqa('/Users/alontalmor/Documents/dev/datasets/SearchQA/data_json/','val')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSMARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.115242Z",
     "start_time": "2018-10-07T09:34:37.078005Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_MSMARCO:\n",
    "    import gzip\n",
    "    def load_msmarco(dirname,filename):\n",
    "        print(os.path.join(dirname,filename +'.gz'))\n",
    "        with gzip.open(os.path.join(dirname,filename +'.gz'),'rb') as myzip:\n",
    "            msmarco = pd.DataFrame(json.loads(myzip.read()))\n",
    "\n",
    "        print(len(msmarco))\n",
    "        msmarco = msmarco[msmarco['answers'].str[0] != 'No Answer Present.']\n",
    "        msmarco = msmarco[msmarco['answers'].str[0] != 'Yes']\n",
    "        msmarco = msmarco[msmarco['answers'].str[0] != 'No']\n",
    "        msmarco = msmarco[msmarco['answers'].str[0] != '']\n",
    "\n",
    "        \n",
    "\n",
    "        # Filter very long answers:\n",
    "        msmarco = msmarco[msmarco['answers'].str[0].apply(len) < 30]\n",
    "        \n",
    "        # filtering if no well formed answers? \n",
    "        # len(Data['msmarco'][Data['msmarco']['wellFormedAnswers'] != '[]'])\n",
    "        \n",
    "        print(len(msmarco))\n",
    "\n",
    "        return msmarco\n",
    "\n",
    "    if USE_MSMARCO and EVAL_SET == 'dev':\n",
    "         Data['MSMARCO'] = load_msmarco('/Users/alontalmor/Documents/dev/datasets/MSMARCO/','dev_v2.1.json')\n",
    "    \n",
    "    # fileter no answer persent, yes and no answers:\n",
    "    \n",
    "    #Data['msmarco']['answers'].str[0].value_counts()[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.122237Z",
     "start_time": "2018-10-07T09:34:37.116725Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # answer exact match comparison\n",
    "    selected_answers = []\n",
    "    for ind,q in Data['MSMARCO'].iterrows():\n",
    "        x = pd.DataFrame(q['passages'])\n",
    "        selected_answers.append(x[x['is_selected'] == 1]['passage_text'].iloc[0])\n",
    "    Data['MSMARCO']['selected_answers'] = selected_answers\n",
    "    Data['MSMARCO'][['answers','selected_answers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.168115Z",
     "start_time": "2018-10-07T09:34:37.124043Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def load_squad(dirname,filename):\n",
    "    with zipfile.ZipFile(os.path.join(dirname,filename +'.zip'),'r') as myzip:\n",
    "        with myzip.open(filename) as myfile:\n",
    "            squad_json = json.load(myfile)\n",
    "\n",
    "    squad_questions = []\n",
    "    contexts = []\n",
    "    for part in squad_json['data']:\n",
    "        for para in part['paragraphs']:\n",
    "            contexts.append(para['context'])\n",
    "            for qas in para['qas']:\n",
    "                question = qas.copy()\n",
    "                question['title'] = part['title']\n",
    "                question['context_id'] = len(contexts) - 1\n",
    "                squad_questions.append(question)\n",
    "    squad_questions = pd.DataFrame(squad_questions)\n",
    "\n",
    "    # removing version 2 samples! \n",
    "    squad_questionsV1 = squad_questions[~squad_questions['is_impossible']].copy(deep=True)\n",
    "    del squad_questionsV1['is_impossible']\n",
    "    del squad_questionsV1['plausible_answers']\n",
    "\n",
    "    # empty entity pages\n",
    "    squad_questionsV1['EntityPages'] = np.empty((len(squad_questionsV1), 0)).tolist()\n",
    "\n",
    "    # empty search results\n",
    "    squad_questionsV1['SearchResults'] = np.empty((len(squad_questionsV1), 0)).tolist()\n",
    "\n",
    "    return squad_questionsV1, contexts\n",
    "    \n",
    "if USE_SQUAD and EVAL_SET == 'dev':\n",
    "     Data['Squad'], org_contexts = load_squad('../data/Squad/','dev-v2.0.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.209154Z",
     "start_time": "2018-10-07T09:34:37.170165Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_TRIVIAQA and EVAL_SET == 'dev':\n",
    "    if USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        with zipfile.ZipFile('../data/TriviaQA/web-dev.json.zip','r') as myzip:\n",
    "            with myzip.open('web-dev.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                Data['TriviaQA'] = pd.DataFrame(questions['Data'])\n",
    "    else:\n",
    "        with zipfile.ZipFile('../data/TriviaQA/unfiltered-web-dev.json.zip','r') as myzip:\n",
    "            with myzip.open('unfiltered-web-dev.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                Data['TriviaQA'] = pd.DataFrame(questions['Data'])\n",
    "            \n",
    "    # empty entity pages\n",
    "    if not USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        Data['TriviaQA']['EntityPages'] = np.empty((len(Data['TriviaQA']), 0)).tolist()\n",
    "\n",
    "    # empty search results\n",
    "    if not USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        Data['TriviaQA']['SearchResults']  = Data['TriviaQA']['SearchResults'].astype(object)\n",
    "        Data['TriviaQA']['SearchResults'] = np.empty((len(Data['TriviaQA']), 0)).tolist()\n",
    "        \n",
    "if USE_TRIVIAQA and EVAL_SET == 'test':\n",
    "    if USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        with zipfile.ZipFile('../data/TriviaQA/web-test-without-answers.json.zip','r') as myzip:\n",
    "            with myzip.open('web-test-without-answers.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                Data['TriviaQA'] = pd.DataFrame(questions['Data'])\n",
    "    # empty entity pages\n",
    "    #Data['TriviaQA']['EntityPages'] = np.empty((len(Data['TriviaQA']), 0)).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplexWebQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.271221Z",
     "start_time": "2018-10-07T09:34:37.210872Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# comparing web triavia-rc dev number of question to unfiltered number of questions\n",
    "if USE_COMPWEBQ and EVAL_SET == 'dev':\n",
    "    rl_input_df = pd.DataFrame()\n",
    "    #data_dir = '/Users/alontalmor/Dropbox/Apps/WebKB/webkb_dev_data/RL_preproc_data/rl_cascade1_epoch0-8/'\n",
    "    data_dir = '../data/V2_dev_splitpoints/'\n",
    "    filename = 'dev.json.zip'\n",
    "    if filename.find('.json.zip') > -1:\n",
    "        print(filename)\n",
    "        with zipfile.ZipFile(data_dir + filename, 'r') as myzip:\n",
    "            with myzip.open(filename.replace('.zip', '')) as myfile:\n",
    "                curr_batch = pd.DataFrame(json.load(myfile))\n",
    "        curr_batch = curr_batch[(curr_batch[['split_part1', 'split_part2']].isnull(\n",
    "        ) * 1.0).sum(axis=1) == 0]  # removing null values\n",
    "        curr_batch['traj_id'] = curr_batch['ID'] + curr_batch['comp'] + curr_batch['split_part1'].str.replace(\" \",\"\") \\\n",
    "                                + ',' + curr_batch['split_part2'].str.replace(\" \",\"\")\n",
    "        if len(rl_input_df) > 0:\n",
    "            len_before_filter = len(curr_batch)\n",
    "            curr_batch = curr_batch[\n",
    "                ~curr_batch['traj_id'].isin(rl_input_df['traj_id'])]\n",
    "        curr_batch['filename'] = filename\n",
    "        rl_input_df = rl_input_df.append(curr_batch, ignore_index=True)\n",
    "\n",
    "    rl_input_df = rl_input_df.set_index('traj_id')\n",
    "\n",
    "    # dropping exact duplicate splits\n",
    "    print('size before drop dups: ' + str(len(rl_input_df)))\n",
    "    rl_input_df = rl_input_df.drop_duplicates(\n",
    "        ['ID', 'comp', 'split_part1', 'split_part2'])\n",
    "    print('size after drop dups: ' + str(len(rl_input_df)))\n",
    "\n",
    "    dataset_filename = '../../../mturk/compqgen/final/complexwebquestions_V1_1/ComplexWebQuestions_dev'\n",
    "    with open(dataset_filename + '.json', 'r') as outfile:\n",
    "        complexwebquestions = pd.DataFrame(json.load(outfile))\n",
    "\n",
    "    rl_input_df = rl_input_df.merge(\n",
    "        pd.DataFrame(complexwebquestions)[['answers', 'ID']], on='ID', how='inner')\n",
    "    rl_input_df.rename(columns={'answers_y': 'answers'}, inplace=True)\n",
    "    del rl_input_df['answers_x']\n",
    "    Data['ComplexWebQuestions'] = rl_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiTableQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.275937Z",
     "start_time": "2018-10-07T09:34:37.273148Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_WIKITABLEQ and EVAL_SET == 'train':\n",
    "    Data['WikiTableQ'] = load_wikitableq('/Users/alontalmor/Dropbox/Backup/QAResearch/ipython/MTurk_TableQA_Rephrasing/','train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.314377Z",
     "start_time": "2018-10-07T09:34:37.278169Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMQA and EVAL_SET == 'train':\n",
    "    Data['ComQA'] = load_comqa('/Users/alontalmor/Documents/dev/datasets/ComQA/','train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSMARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.319968Z",
     "start_time": "2018-10-07T09:34:37.316666Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_MSMARCO and EVAL_SET == 'train':\n",
    "    Data['MSMARCO'] = load_msmarco('/Users/alontalmor/Documents/dev/datasets/MSMARCO/','train_v2.1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.324870Z",
     "start_time": "2018-10-07T09:34:37.321655Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_SQUAD and EVAL_SET == 'train':\n",
    "    Data['Squad'], org_contexts = load_squad('../data/Squad/','train-v2.0.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.350151Z",
     "start_time": "2018-10-07T09:34:37.326669Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_TRIVIAQA and EVAL_SET == 'train':\n",
    "    if USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        with zipfile.ZipFile('../data/TriviaQA/web-train.json.zip','r') as myzip:\n",
    "            with myzip.open('web-train.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                triviaqa_dataset = pd.DataFrame(questions['Data'])\n",
    "    else:\n",
    "        with zipfile.ZipFile('../data/TriviaQA/unfiltered-web-train.json.zip','r') as myzip:\n",
    "            with myzip.open('unfiltered-web-train.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                triviaqa_dataset = pd.DataFrame(questions['Data'])\n",
    "            \n",
    "    # empty entity pages\n",
    "    triviaqa_dataset['EntityPages'] = np.empty((len(triviaqa_dataset), 0)).tolist()\n",
    "\n",
    "    # empty search results \n",
    "    if not USE_TRIVIAQA_ORG_CONTEXT:\n",
    "        triviaqa_dataset['SearchResults']  = triviaqa_dataset['SearchResults'].astype(object)\n",
    "        triviaqa_dataset['SearchResults'] = np.empty((len(triviaqa_dataset), 0)).tolist()\n",
    "    \n",
    "    Data['TriviaQA'] = triviaqa_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplexWebQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.448604Z",
     "start_time": "2018-10-07T09:34:37.352730Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ and EVAL_SET == 'train':\n",
    "    rl_input_df = pd.DataFrame()\n",
    "    #data_dir = '/Users/alontalmor/Dropbox/Apps/WebKB/webkb_dev_data/RL_train_data/rl_cascade1_epoch0-8/'\n",
    "    # V2 Code\n",
    "    data_dir = '../data/V2_train_splitpoints/'\n",
    "    for dirname, dirnames, filenames in os.walk(data_dir):\n",
    "\n",
    "        # making sure noisy sup is added first (because of the default MIN_REWARD_TRESH values\n",
    "        #if 'noisy_sup_rewarded.json.zip' in filenames:\n",
    "        #    filenames.remove('noisy_sup_rewarded.json.zip')\n",
    "        #    filenames = ['noisy_sup_rewarded.json.zip'] + filenames\n",
    "        # V2 code\n",
    "        if 'train.json.zip' in filenames:\n",
    "            filenames.remove('train.json.zip')\n",
    "            filenames = ['train.json.zip'] + filenames\n",
    "\n",
    "        for filename in filenames[0:2]:\n",
    "\n",
    "            if filename.find('.json.zip')>-1:\n",
    "                print(filename)\n",
    "                with zipfile.ZipFile(data_dir + filename,'r') as myzip:\n",
    "                    with myzip.open(filename.replace('.zip','')) as myfile:\n",
    "                        curr_batch = pd.DataFrame(json.load(myfile))\n",
    "                curr_batch = curr_batch[(curr_batch[['split_part1', 'split_part2']].isnull() * 1.0).sum(axis=1) == 0] # removing null values\n",
    "                # V2 Code\n",
    "                if len(rl_input_df) > 0:\n",
    "                    curr_batch = curr_batch[curr_batch['ID'].isin(rl_input_df['ID'])]\n",
    "\n",
    "                curr_batch['traj_id'] = curr_batch['ID'] + curr_batch['comp'] + curr_batch['split_part1'].str.replace(\" \",\"\") \\\n",
    "                                            + ',' + curr_batch['split_part2'].str.replace(\" \",\"\")\n",
    "                if len(rl_input_df)>0:\n",
    "                    len_before_filter = len(curr_batch)\n",
    "                    curr_batch = curr_batch[~curr_batch['traj_id'].isin(rl_input_df['traj_id'])]\n",
    "                curr_batch['filename'] = filename\n",
    "                rl_input_df = rl_input_df.append(curr_batch, ignore_index=True)\n",
    "\n",
    "    dataset_filename = '../../../mturk/compqgen/final/complexwebquestions_V1_1/ComplexWebQuestions_train'\n",
    "    with open(dataset_filename + '.json', 'r') as outfile:\n",
    "        complexwebquestions = pd.DataFrame(json.load(outfile))\n",
    "\n",
    "    rl_input_df = rl_input_df.merge(\n",
    "        pd.DataFrame(complexwebquestions)[['answers', 'ID']], on='ID', how='inner')\n",
    "    rl_input_df.rename(columns={'answers_y': 'answers'}, inplace=True)\n",
    "    del rl_input_df['answers_x']        \n",
    "\n",
    "    rl_input_df = rl_input_df.set_index('traj_id')\n",
    "\n",
    "    # dropping exact duplicate splits\n",
    "    print('size before drop dups: ' + str(len(rl_input_df)))\n",
    "    rl_input_df = rl_input_df.drop_duplicates(['ID', 'comp', 'split_part1', 'split_part2'])\n",
    "    print('size after drop dups: ' + str(len(rl_input_df)))\n",
    "    \n",
    "    # checking overlab between V1 training question and V2\n",
    "    #dataset_filename = '../../mturk/compqgen/final/complexwebquestions/ComplexWebQuestions_train'\n",
    "    #with open(dataset_filename + '.json', 'r') as outfile:\n",
    "    #    complexwebquestions_org = pd.DataFrame(json.load(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.456482Z",
     "start_time": "2018-10-07T09:34:37.450388Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ:\n",
    "    dataset_filename = '../data/ComplexWebQuestions_' + EVAL_SET\n",
    "    with open(dataset_filename + '.json', 'r') as outfile:\n",
    "        complexwebquestions_org = pd.DataFrame(json.load(outfile)).set_index('ID')\n",
    "\n",
    "    rl_input_df.loc[rl_input_df['comp'] == 'composition','composition_answer'] = \\\n",
    "        list(complexwebquestions_org.loc[rl_input_df[rl_input_df['comp'] == 'composition']['ID'],'composition_answer'].astype(object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.495586Z",
     "start_time": "2018-10-07T09:34:37.458059Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ:\n",
    "    questions = []   \n",
    "    for ind in tqdm(range(len(rl_input_df)), total=len(rl_input_df), ncols=80, desc=\"scoring\"):\n",
    "        question = rl_input_df.iloc[ind]\n",
    "        if question['comp'] == 'conjunction':\n",
    "            q_copied = question.copy()\n",
    "            questions.append(q_copied)\n",
    "            if ADD_SPLITS_TO_TRAIN:\n",
    "                q_copied = question.copy()\n",
    "                q_copied['question'] = question['split_part1']\n",
    "                questions.append(q_copied)\n",
    "                q_copied = question.copy()\n",
    "                q_copied['question'] = question['split_part2']\n",
    "                questions.append(q_copied)\n",
    "        elif question['comp'] == 'composition':\n",
    "            q_copied = question.copy()\n",
    "            q_copied['ID']\n",
    "            questions.append(q_copied)\n",
    "            if ADD_SPLITS_TO_TRAIN:\n",
    "                q_copied = question.copy()\n",
    "                q_copied['question'] = question['split_part1']\n",
    "                q_copied['answers'] = [{'aliases':[],'answer':question['composition_answer']}]\n",
    "                questions.append(q_copied)\n",
    "                q_copied = question.copy()\n",
    "                q_copied['question'] = question['split_part2']\n",
    "                q_copied['question'] = q_copied['question'].replace('%composition',question['composition_answer'])\n",
    "                questions.append(q_copied)\n",
    "        else:\n",
    "            q_copied = question.copy()\n",
    "            questions.append(q_copied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.505072Z",
     "start_time": "2018-10-07T09:34:37.497792Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ:\n",
    "    questions = pd.DataFrame(questions)\n",
    "    # dropping exact duplicate splits\n",
    "    print('size before drop dups: ' + str(len(questions)))\n",
    "    questions = questions.drop_duplicates(['question'])\n",
    "    print('size after drop dups: ' + str(len(questions)))\n",
    "    questions = questions.reset_index(drop=True)\n",
    "    Data['ComplexWebQuestions'] = questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplexWebQuestions to TriviaQA format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to triviaqa format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev and train are converted in the same place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:37.509986Z",
     "start_time": "2018-10-07T09:34:37.507273Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "Data_triviaqa_format = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:39.737048Z",
     "start_time": "2018-10-07T09:34:37.511814Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "appending answers: 100%|██████████████████| 6324/6324 [00:01<00:00, 3397.34it/s]\n"
     ]
    }
   ],
   "source": [
    "if USE_COMQA:\n",
    "    questions = Data['ComQA']\n",
    "    # removing cases with empty answers\n",
    "    questions = questions[(questions['answers'].apply(len) == 1) & (questions['answers'].str[0] != '')]\n",
    "    if PRODUCE_ONLY_SAMPLE:\n",
    "        questions = questions[0:100]\n",
    "        \n",
    "    questions_triviaqa_format = pd.DataFrame()\n",
    "    questions_triviaqa_format['QuestionId'] = questions['ID']\n",
    "    questions_triviaqa_format['Question'] = questions['question']\n",
    " \n",
    "    questions_triviaqa_format['SearchResults'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['EntityPages'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['QuestionSource'] = ''\n",
    "    all_answers = []\n",
    "    for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"appending answers\"):\n",
    "        filtered_answer = []\n",
    "        for answer in q['answers']:\n",
    "            if len(answer) > 0:\n",
    "                answer = answer.split('(')[0]\n",
    "                answer = answer.replace('https://en.wikipedia.org/wiki/','')\n",
    "                answer = answer.replace('_',' ')\n",
    "                filtered_answer.append(answer)\n",
    "        \n",
    "        \n",
    "        triviaqa_formated_answers = {'Aliases':[],'NormalizedAliases':[], \\\n",
    "                                    'NormalizedValue':'', \\\n",
    "                                     'Type':'FreeForm','Value':''}\n",
    "        triviaqa_formated_answers['Value'] = filtered_answer[0]\n",
    "        triviaqa_formated_answers['NormalizedValue'] = ' '.join(word_tokenize(filtered_answer[0].lower()))\n",
    "        aliases = [answer for answer in filtered_answer]\n",
    "        aliases = list(set(aliases))\n",
    "        triviaqa_formated_answers['Aliases'] = aliases\n",
    "        \n",
    "        triviaqa_formated_answers['NormalizedAliases'] = \\\n",
    "            [' '.join(word_tokenize(word.lower())) for word in triviaqa_formated_answers['Aliases']]\n",
    "        all_answers.append(triviaqa_formated_answers)\n",
    "\n",
    "    questions_triviaqa_format['Answer'] = all_answers\n",
    "    questions_triviaqa_format = questions_triviaqa_format[questions_triviaqa_format['Answer'].notnull()] \n",
    "    \n",
    "    questions_triviaqa_format = questions_triviaqa_format.drop_duplicates(subset='QuestionId')\n",
    "    \n",
    "    Data_triviaqa_format['ComQA'] = questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiTableQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:39.786268Z",
     "start_time": "2018-10-07T09:34:39.738907Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_WIKITABLEQ:\n",
    "    questions = Data['WikiTableQ']\n",
    "    if PRODUCE_ONLY_SAMPLE:\n",
    "        questions = questions[0:100]\n",
    "        \n",
    "    questions_triviaqa_format = pd.DataFrame()\n",
    "    questions_triviaqa_format['QuestionId'] = questions['qid']\n",
    "    questions_triviaqa_format['Question'] = questions['rephrased_question']\n",
    " \n",
    "    questions_triviaqa_format['SearchResults'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['EntityPages'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['QuestionSource'] = ''\n",
    "    all_answers = []\n",
    "    for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"appending answers\"):\n",
    "        filtered_answer = [str(q['answers'])]\n",
    "        triviaqa_formated_answers = {'Aliases':[],'NormalizedAliases':[], \\\n",
    "                                    'NormalizedValue':'', \\\n",
    "                                     'Type':'FreeForm','Value':''}\n",
    "        triviaqa_formated_answers['Value'] = filtered_answer[0]\n",
    "        triviaqa_formated_answers['NormalizedValue'] = ' '.join(word_tokenize(filtered_answer[0].lower()))\n",
    "        aliases = [answer for answer in filtered_answer]\n",
    "        aliases = list(set(aliases))\n",
    "        triviaqa_formated_answers['Aliases'] = aliases\n",
    "        \n",
    "        triviaqa_formated_answers['NormalizedAliases'] = \\\n",
    "            [' '.join(word_tokenize(word.lower())) for word in triviaqa_formated_answers['Aliases']]\n",
    "        all_answers.append(triviaqa_formated_answers)\n",
    "\n",
    "    questions_triviaqa_format['Answer'] = all_answers\n",
    "    questions_triviaqa_format = questions_triviaqa_format[questions_triviaqa_format['Answer'].notnull()] \n",
    "    \n",
    "    Data_triviaqa_format['WikiTableQ'] = questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSMARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:39.867796Z",
     "start_time": "2018-10-07T09:34:39.788216Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if USE_MSMARCO:\n",
    "    questions = Data['MSMARCO']\n",
    "    questions_triviaqa_format = pd.DataFrame()\n",
    "    questions_triviaqa_format['QuestionId'] = questions['query_id']\n",
    "    questions_triviaqa_format['Question'] = questions['query']\n",
    "    if USE_MSMARCO_ORG_CONTEXT:\n",
    "        all_contexts = []\n",
    "        for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"org context\"): \n",
    "            passages = []\n",
    "            for snippet in q['passages']:\n",
    "                passages += [{'title':'','snippet':snippet['passage_text']}]\n",
    "            all_contexts.append(passages)\n",
    "        questions_triviaqa_format['SearchResults'] = all_contexts\n",
    "    else:\n",
    "        questions_triviaqa_format['SearchResults'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['EntityPages'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['QuestionSource'] = ''\n",
    "    all_answers = []\n",
    "    for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"scoring\"):\n",
    "        filtered_answer = []\n",
    "        for answer in q['answers']:\n",
    "            if len(answer) > 0:\n",
    "                filtered_answer.append(answer)\n",
    "        \n",
    "        \n",
    "        triviaqa_formated_answers = {'Aliases':[],'NormalizedAliases':[], \\\n",
    "                                    'NormalizedValue':'', \\\n",
    "                                     'Type':'FreeForm','Value':''}\n",
    "        triviaqa_formated_answers['Value'] = filtered_answer[0]\n",
    "        triviaqa_formated_answers['NormalizedValue'] = ' '.join(word_tokenize(filtered_answer[0].lower()))\n",
    "        aliases = [answer for answer in filtered_answer]\n",
    "        aliases = list(set(aliases))\n",
    "        triviaqa_formated_answers['Aliases'] = aliases\n",
    "        \n",
    "        triviaqa_formated_answers['NormalizedAliases'] = \\\n",
    "            [' '.join(word_tokenize(word.lower())) for word in triviaqa_formated_answers['Aliases']]\n",
    "        all_answers.append(triviaqa_formated_answers)\n",
    "\n",
    "    questions_triviaqa_format['Answer'] = all_answers\n",
    "    questions_triviaqa_format = questions_triviaqa_format[questions_triviaqa_format['Answer'].notnull()] \n",
    "    \n",
    "    Data_triviaqa_format['MSMARCO'] = questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:39.943924Z",
     "start_time": "2018-10-07T09:34:39.869663Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_SQUAD:\n",
    "    questions = Data['Squad']\n",
    "    if PRODUCE_ONLY_SAMPLE:\n",
    "        questions = questions[0:100]\n",
    "        \n",
    "    questions_triviaqa_format = pd.DataFrame()\n",
    "    questions_triviaqa_format['QuestionId'] = questions['id']\n",
    "    questions_triviaqa_format['Question'] = questions['question']\n",
    "    if USE_SQUAD_ORG_CONTEXT:\n",
    "        all_contexts = []\n",
    "        for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"org context\"): \n",
    "            all_contexts.append([{'title':'','snippet':org_contexts[q['context_id']]}])\n",
    "        questions_triviaqa_format['SearchResults'] = all_contexts\n",
    "    else:\n",
    "        questions_triviaqa_format['SearchResults'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['EntityPages'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['QuestionSource'] = ''\n",
    "    all_answers = []\n",
    "    for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"appending answers\"):\n",
    "        filtered_answer = []\n",
    "        for answer in q['answers']:\n",
    "            if len(answer['text']) > 0:\n",
    "                filtered_answer.append(answer)\n",
    "        \n",
    "        \n",
    "        triviaqa_formated_answers = {'Aliases':[],'NormalizedAliases':[], \\\n",
    "                                    'NormalizedValue':'', \\\n",
    "                                     'Type':'FreeForm','Value':''}\n",
    "        triviaqa_formated_answers['Value'] = filtered_answer[0]['text']\n",
    "        triviaqa_formated_answers['NormalizedValue'] = ' '.join(word_tokenize(filtered_answer[0]['text'].lower()))\n",
    "        aliases = [answer['text'] for answer in filtered_answer]\n",
    "        aliases = list(set(aliases))\n",
    "        triviaqa_formated_answers['Aliases'] = aliases\n",
    "        \n",
    "        triviaqa_formated_answers['NormalizedAliases'] = \\\n",
    "            [' '.join(word_tokenize(word.lower())) for word in triviaqa_formated_answers['Aliases']]\n",
    "        all_answers.append(triviaqa_formated_answers)\n",
    "\n",
    "    questions_triviaqa_format['Answer'] = all_answers\n",
    "    questions_triviaqa_format = questions_triviaqa_format[questions_triviaqa_format['Answer'].notnull()] \n",
    "    \n",
    "    Data_triviaqa_format['Squad'] = questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComplexWebQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.011011Z",
     "start_time": "2018-10-07T09:34:39.946003Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ:\n",
    "    questions = Data['ComplexWebQuestions']\n",
    "    if PRODUCE_ONLY_SAMPLE:\n",
    "        questions = questions[0:100]\n",
    "    questions_triviaqa_format = pd.DataFrame()\n",
    "    questions_triviaqa_format['QuestionId'] = questions['ID'] + '_' + questions.index.astype(str)\n",
    "    questions_triviaqa_format['Question'] = questions['question']\n",
    "    questions_triviaqa_format['SearchResults'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['EntityPages'] = [[] for x in range(len(questions_triviaqa_format))]\n",
    "    questions_triviaqa_format['QuestionSource'] = ''\n",
    "    all_answers = []\n",
    "    for ind,q in tqdm(questions.iterrows(),total=len(questions), ncols=80, desc=\"scoring\"):\n",
    "        if q['answers'][0]['answer'] == None or q['answers'][0]['answer'] == '':\n",
    "            all_answers.append(None)\n",
    "        else:\n",
    "            filtered_answer = []\n",
    "            for answer in q['answers']:\n",
    "                if len(answer['answer']) > 0:\n",
    "                    filtered_answer.append(answer)\n",
    "\n",
    "            triviaqa_formated_answers = {'Aliases':[],'NormalizedAliases':[], \\\n",
    "                                        'NormalizedValue':'', \\\n",
    "                                         'Type':'FreeForm','Value':''}\n",
    "            triviaqa_formated_answers['Value'] = filtered_answer[0]['answer']\n",
    "            triviaqa_formated_answers['NormalizedValue'] = ' '.join(word_tokenize(filtered_answer[0]['answer'].lower()))\n",
    "            for answer in filtered_answer:\n",
    "                triviaqa_formated_answers['Aliases'] += answer['aliases']\n",
    "                triviaqa_formated_answers['Aliases'].append(answer['answer'])\n",
    "\n",
    "            triviaqa_formated_answers['NormalizedAliases'] = \\\n",
    "                [' '.join(word_tokenize(word.lower())) for word in triviaqa_formated_answers['Aliases']]\n",
    "            all_answers.append(triviaqa_formated_answers)\n",
    "\n",
    "    questions_triviaqa_format['Answer'] = all_answers\n",
    "    questions_triviaqa_format = questions_triviaqa_format[questions_triviaqa_format['Answer'].notnull()]  \n",
    "    Data_triviaqa_format['ComplexWebQuestions'] = questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.015736Z",
     "start_time": "2018-10-07T09:34:40.012676Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if USE_TRIVIAQA:\n",
    "    if PRODUCE_ONLY_SAMPLE:\n",
    "        Data['TriviaQA'] = Data['TriviaQA'][0:100]\n",
    "    Data_triviaqa_format['TriviaQA'] = Data['TriviaQA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending snippets to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "google snippets are appended to all sub-datasets in the same manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From local mongo (currently only for ComplexWebQuestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.022667Z",
     "start_time": "2018-10-07T09:34:40.017572Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ and WRITE_EVIDENCE:\n",
    "    MONGODB_URI = 'mongodb://127.0.0.1:27017/webkb'\n",
    "    mongo_client = pymongo.MongoClient(MONGODB_URI)\n",
    "    db = mongo_client.get_default_database()\n",
    "    SearchCache = db['SearchResults_Cache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.047568Z",
     "start_time": "2018-10-07T09:34:40.025029Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if USE_COMPWEBQ:\n",
    "    if WRITE_EVIDENCE:\n",
    "        found = 0\n",
    "        questions_triviaqa_format = Data_triviaqa_format['ComplexWebQuestions']\n",
    "        questions_triviaqa_format = questions_triviaqa_format.set_index('QuestionId')\n",
    "        questions_triviaqa_format['SearchResults'] = None\n",
    "        questions_triviaqa_format['SearchResults'] = questions_triviaqa_format['SearchResults'].astype(object)\n",
    "        for QuestionId,question in tqdm(questions_triviaqa_format.iterrows(), total=len(questions_triviaqa_format), ncols=80,\\\n",
    "                        desc=\"appending google search results\"):\n",
    "            CacheResults = SearchCache.find(\n",
    "                {'querystr': question['Question'], \"page\": 0, \"type\": 'SCREEN'})\n",
    "            CacheResults_Count = CacheResults.count()\n",
    "            if CacheResults_Count>0:\n",
    "                found += 1\n",
    "                cahched_item = CacheResults.next()\n",
    "                questions_triviaqa_format.at[QuestionId,'SearchResults'] = cahched_item['results']\n",
    "        questions_triviaqa_format = questions_triviaqa_format.reset_index()\n",
    "\n",
    "        Data_triviaqa_format['ComplexWebQuestions_Googled'] = questions_triviaqa_format\n",
    "        del Data_triviaqa_format['ComplexWebQuestions']\n",
    "    else:\n",
    "        Data_triviaqa_format['ComplexWebQuestions_Googled'] = Data_triviaqa_format.pop('ComplexWebQuestions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.096203Z",
     "start_time": "2018-10-07T09:34:40.049345Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def append_google_from_files(questions_triviaqa_format,googled_dir):\n",
    "    question_count = 0\n",
    "    \n",
    "\n",
    "    questions_triviaqa_format = questions_triviaqa_format.set_index('QuestionId')\n",
    "    questions_triviaqa_format['SearchResults'] = None\n",
    "    questions_triviaqa_format['SearchResults'] = questions_triviaqa_format['SearchResults'].astype(object)\n",
    "\n",
    "    for dirname, dirnames, filenames in os.walk(googled_dir):\n",
    "        for filename in tqdm(filenames, total=len(filenames), ncols=80, desc='iterating over all googled files'):\n",
    "            with zipfile.ZipFile(googled_dir + '/' + filename,'r') as myzip:\n",
    "                with myzip.open(filename.replace('.zip','')) as myfile:\n",
    "                    googled = json.load(myfile)\n",
    "                    \n",
    "            for googled_question in googled:\n",
    "                question_count += 1\n",
    "                if 'QuestionId' in googled_question:\n",
    "                    ID = googled_question['QuestionId']\n",
    "                elif 'id' in googled_question:\n",
    "                    ID = googled_question['id']\n",
    "                else:\n",
    "                    ID = googled_question['ID']\n",
    "                \n",
    "                \n",
    "                if ID in questions_triviaqa_format.index:\n",
    "                    if questions_triviaqa_format.at[ID,'SearchResults'] is None \\\n",
    "                        or questions_triviaqa_format.at[ID,'SearchResults'] == 0:\n",
    "                        questions_triviaqa_format.at[ID,'SearchResults'] = googled_question['google_results']\n",
    "                    \n",
    "    questions_triviaqa_format = questions_triviaqa_format.reset_index()\n",
    "    print('number of questions googled')\n",
    "    print(question_count)\n",
    "    print((questions_triviaqa_format['SearchResults'].apply(len)==0).sum())\n",
    "    \n",
    "    return questions_triviaqa_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.108035Z",
     "start_time": "2018-10-07T09:34:40.098294Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# ComQA \n",
    "if USE_COMQA:\n",
    "    if WRITE_EVIDENCE:\n",
    "        if EVAL_SET == 'dev':\n",
    "            Data_triviaqa_format['ComQA_Googled'] = append_google_from_files(Data_triviaqa_format['ComQA'], \\\n",
    "                    '/Users/alontalmor/Dropbox/Apps/WebKB/ComQA/dev')\n",
    "        else:\n",
    "            Data_triviaqa_format['ComQA_Googled'] = append_google_from_files(Data_triviaqa_format['ComQA'], \\\n",
    "                    '/Users/alontalmor/Dropbox/Apps/WebKB/ComQA/train')\n",
    "            \n",
    "        Data_triviaqa_format['ComQA_Googled'] = Data_triviaqa_format['ComQA_Googled'][ \\\n",
    "                Data_triviaqa_format['ComQA_Googled']['SearchResults'].notnull()]\n",
    "        del Data_triviaqa_format['ComQA']\n",
    "    else:\n",
    "        Data_triviaqa_format['ComQA_Googled'] = Data_triviaqa_format.pop('ComQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.119509Z",
     "start_time": "2018-10-07T09:34:40.109903Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# WikiTableQ \n",
    "if USE_WIKITABLEQ:\n",
    "    if WRITE_EVIDENCE:\n",
    "        if EVAL_SET == 'dev':\n",
    "            Data_triviaqa_format['WikiTableQ_Googled'] = append_google_from_files(Data_triviaqa_format['WikiTableQ'], \\\n",
    "                                                                       '../data/WikiTableQuestions_CF')\n",
    "        else:\n",
    "            Data_triviaqa_format['WikiTableQ_Googled'] = append_google_from_files(Data_triviaqa_format['WikiTableQ'], \\\n",
    "                                                                   '../data/WikiTableQuestions_CF')  \n",
    "            \n",
    "        Data_triviaqa_format['WikiTableQ_Googled'] = Data_triviaqa_format['WikiTableQ_Googled'][ \\\n",
    "                Data_triviaqa_format['WikiTableQ_Googled']['SearchResults'].notnull()]\n",
    "        del Data_triviaqa_format['WikiTableQ']\n",
    "    else:\n",
    "        Data_triviaqa_format['WikiTableQ_Googled'] = Data_triviaqa_format.pop('WikiTableQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.131447Z",
     "start_time": "2018-10-07T09:34:40.121991Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# TriviaQA\n",
    "if USE_TRIVIAQA and USE_TRIVIAQA_ORG_CONTEXT:\n",
    "    Data_triviaqa_format['TriviaQA_Org'] = Data_triviaqa_format.pop('TriviaQA')\n",
    "elif USE_TRIVIAQA and SEARCHRESULTS_FROM_FILES:\n",
    "    if WRITE_EVIDENCE:\n",
    "        if EVAL_SET == 'dev':\n",
    "            Data_triviaqa_format['TriviaQA_Googled'] = append_google_from_files(Data_triviaqa_format['TriviaQA'], \\\n",
    "                                                                       '../data/triviaqa_googled_dev')\n",
    "        else:\n",
    "            Data_triviaqa_format['TriviaQA_Googled'] = append_google_from_files(Data_triviaqa_format['TriviaQA'], \\\n",
    "                                                                   '../data/triviaqa_googled_train')\n",
    "        del Data_triviaqa_format['TriviaQA']\n",
    "    else:\n",
    "        Data_triviaqa_format['TriviaQA_Googled'] = Data_triviaqa_format.pop('TriviaQA')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.141387Z",
     "start_time": "2018-10-07T09:34:40.133484Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# MSMARCO\n",
    "if USE_MSMARCO and USE_MSMARCO_ORG_CONTEXT:\n",
    "    Data_triviaqa_format['MSMARCO_Org'] = Data_triviaqa_format.pop('MSMARCO')\n",
    "elif USE_MSMARCO and SEARCHRESULTS_FROM_FILES:\n",
    "    if WRITE_EVIDENCE:\n",
    "        if EVAL_SET == 'dev':\n",
    "            Data_triviaqa_format['MSMARCO_Googled'] = append_google_from_files(Data_triviaqa_format['MSMARCO'], \\\n",
    "                                                                       '/Users/alontalmor/Dropbox/Apps/WebKB/MSMARCO/dev')\n",
    "        else:\n",
    "            Data_triviaqa_format['MSMARCO_Googled'] = append_google_from_files(Data_triviaqa_format['MSMARCO'], \\\n",
    "                                                                   '/Users/alontalmor/Dropbox/Apps/WebKB/MSMARCO/train')\n",
    "        del Data_triviaqa_format['MSMARCO']\n",
    "    else:\n",
    "        Data_triviaqa_format['MSMARCO_Googled'] = Data_triviaqa_format.pop('MSMARCO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.150700Z",
     "start_time": "2018-10-07T09:34:40.142929Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Squad \n",
    "if USE_SQUAD and USE_SQUAD_ORG_CONTEXT:\n",
    "    Data_triviaqa_format['Squad_Org'] = Data_triviaqa_format.pop('Squad')\n",
    "elif USE_SQUAD and SEARCHRESULTS_FROM_FILES:\n",
    "    if WRITE_EVIDENCE:\n",
    "        if EVAL_SET == 'dev':\n",
    "            Data_triviaqa_format['Squad_Googled'] = append_google_from_files(Data_triviaqa_format['Squad'], \\\n",
    "                                                                       '../data/Squad/dev')\n",
    "        else:\n",
    "            Data_triviaqa_format['Squad_Googled'] = append_google_from_files(Data_triviaqa_format['Squad'], \\\n",
    "                                                                   '../data/Squad/train')  \n",
    "        del Data_triviaqa_format['Squad']\n",
    "    else:\n",
    "        Data_triviaqa_format['Squad_Googled'] = Data_triviaqa_format.pop('Squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.172851Z",
     "start_time": "2018-10-07T09:34:40.152536Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "ComQA_Googled\n",
      "print how many question we found google results for\n",
      "0\n",
      "final question count\n",
      "6275\n"
     ]
    }
   ],
   "source": [
    "# Post PostProcessing\n",
    "if EVAL_SET != 'test':\n",
    "    for dataset in Data_triviaqa_format.keys():\n",
    "        print('---------------------------------')\n",
    "        print(dataset)\n",
    "        Data_triviaqa_format[dataset] = \\\n",
    "            Data_triviaqa_format[dataset][Data_triviaqa_format[dataset]['SearchResults'].notnull()]\n",
    "\n",
    "        print('print how many question we found google results for')\n",
    "        print((Data_triviaqa_format[dataset]['SearchResults'].apply(len)>0).sum())\n",
    "\n",
    "\n",
    "        Data_triviaqa_format[dataset] = \\\n",
    "            Data_triviaqa_format[dataset][Data_triviaqa_format[dataset]['SearchResults'].notnull()]\n",
    "\n",
    "        Data_triviaqa_format[dataset] = \\\n",
    "            Data_triviaqa_format[dataset][Data_triviaqa_format[dataset]['Answer'].notnull()]\n",
    "\n",
    "        print('final question count')\n",
    "        print(len(Data_triviaqa_format[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T08:52:27.539131Z",
     "start_time": "2018-07-12T08:52:27.536603Z"
    }
   },
   "source": [
    "# Combine all datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation also supports sampling (to reduce size or change number of examples from each dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.193469Z",
     "start_time": "2018-10-07T09:34:40.174712Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# combining all the training sets\n",
    "questions_triviaqa_format = pd.DataFrame()\n",
    "for dataset in Data_triviaqa_format.keys():\n",
    "    Data_triviaqa_format[dataset]['dataset'] = dataset\n",
    "    questions_triviaqa_format = \\\n",
    "        questions_triviaqa_format.append(Data_triviaqa_format[dataset],ignore_index=True)\n",
    "if EVAL_SET == 'train' and LIMIT_TRAIN_SIZE != -1:\n",
    "    if len(questions_triviaqa_format) >= LIMIT_TRAIN_SIZE:\n",
    "        questions_triviaqa_format = questions_triviaqa_format.sample(n=LIMIT_TRAIN_SIZE)\n",
    "        \n",
    "if EVAL_SET == 'dev':\n",
    "    # We don't need more than 10000 in the mixed dev set.\n",
    "    if len(questions_triviaqa_format) >= 10000:\n",
    "        questions_triviaqa_format = questions_triviaqa_format.sample(n=10000)\n",
    "    \n",
    "del Data_triviaqa_format\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.275819Z",
     "start_time": "2018-10-07T09:34:40.195138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>Question</th>\n",
       "      <th>SearchResults</th>\n",
       "      <th>EntityPages</th>\n",
       "      <th>QuestionSource</th>\n",
       "      <th>Answer</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3cac9c75821103eef095a4c3a5d8df11</td>\n",
       "      <td>who does the voice of carl in phineas and ferb?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['tyler alexander mann'], 'NormalizedAliases': ['tyler alexander mann'], 'NormalizedValue': 'tyler alexander mann', 'Type': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b414d23c35cfe20dd6dc425959fc3f83</td>\n",
       "      <td>who is the voice of carl in phineas and ferb?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['tyler alexander mann'], 'NormalizedAliases': ['tyler alexander mann'], 'NormalizedValue': 'tyler alexander mann', 'Type': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cacf77ba23eab9597e71497c7bf38b02</td>\n",
       "      <td>the first black president of mexico?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['vicente guerrero'], 'NormalizedAliases': ['vicente guerrero'], 'NormalizedValue': 'vicente guerrero', 'Type': 'FreeForm', ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>544312c8d0a375647434a3ad28d908c4</td>\n",
       "      <td>who is queens elizabeth's the 2nd mother?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['queen elizabeth the queen mother'], 'NormalizedAliases': ['queen elizabeth the queen mother'], 'NormalizedValue': 'queen e...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efd8744ce9833eea1dadcc3478ffd0ef</td>\n",
       "      <td>who plays james potter in the harry potter films?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['robbie jarvis'], 'NormalizedAliases': ['robbie jarvis'], 'NormalizedValue': 'robbie jarvis', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>617d233b6ada1f7762b66c098772e4fa</td>\n",
       "      <td>who is james potter the harry potter father?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['robbie jarvis'], 'NormalizedAliases': ['robbie jarvis'], 'NormalizedValue': 'robbie jarvis', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8d708a6eabb7cc66ba7bc4d5eb68ac61</td>\n",
       "      <td>where was the ed sullivan show located?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['ed sullivan theater'], 'NormalizedAliases': ['ed sullivan theater'], 'NormalizedValue': 'ed sullivan theater', 'Type': 'Fr...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14584b3ec3743217779b1f0816f3b231</td>\n",
       "      <td>hitler became chancellor of germany in what year?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e071afe9a67e3b6ca98172c8072afb68</td>\n",
       "      <td>what year did hitler become chancellor of germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a0b5787c102df440290f0234a916e91a</td>\n",
       "      <td>what year was hitler elected the chancellor of germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b16ceaf42a41e8118b8b5a2aecc3487c</td>\n",
       "      <td>in which year did hitler become the chancellor of germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffed58a80204fe8ccfdbd75d1e2ac98c</td>\n",
       "      <td>what year did adolf hitler become chancellor for germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>92ded5a964c6e87640da3dca40b00430</td>\n",
       "      <td>which date did hitler become chancellor of germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3e8ddd2672d996dbbf2759ab4f93139f</td>\n",
       "      <td>what was rick riordan's first book he wrote?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5cb7df0fdbfb4d83d68cbeda6bb487b7</td>\n",
       "      <td>what was rick riordan's first book written?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6af6dac495f74f8786549579bf2e59a4</td>\n",
       "      <td>what was the first book rick riordan wrote?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2dac89a36c4dc164490ac342b3b4bca6</td>\n",
       "      <td>what is rick riordans first kids book?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>af59c329333783861a64c0e51ba6e890</td>\n",
       "      <td>when was remember the titans filmed?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['2000'], 'NormalizedAliases': ['2000'], 'NormalizedValue': '2000', 'Type': 'FreeForm', 'Value': '2000'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f725f241f3b29809ada8225a20648e32</td>\n",
       "      <td>when was the movie remember the titans filmed?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['2000'], 'NormalizedAliases': ['2000'], 'NormalizedValue': '2000', 'Type': 'FreeForm', 'Value': '2000'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dfef6760c16e010d43dc017dc81b67cc</td>\n",
       "      <td>largest city located along the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0b2c7b7591bcefffd4c4802ca2d609ba</td>\n",
       "      <td>what largest city in africa is on the banks of the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4823b21d6fea864406e56d4bac813b69</td>\n",
       "      <td>largest city on the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>598bdf7a5ed63160074c2ffb6107c34c</td>\n",
       "      <td>largest city by the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>63b73b10883c9dbda112b9789bb2d908</td>\n",
       "      <td>largest city in africa built on the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>846db2e66d0c26c9c72e33747e7798e3</td>\n",
       "      <td>what is the largest city in africa that is on the banks of the nile river?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50ead345b027a8bc72c51838af603d33</td>\n",
       "      <td>how many us presidents have there been?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['44'], 'NormalizedAliases': ['44'], 'NormalizedValue': '44', 'Type': 'FreeForm', 'Value': '44'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>800f535cc14908a8dea2911f6e11d815</td>\n",
       "      <td>where is trinidad an tobago located?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39202a3b3c243beefa2c401532b3dd6f</td>\n",
       "      <td>on what continent is tobago and trinidad located?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cc9948d61187ec0b9febe3918c254882</td>\n",
       "      <td>where is trinidad and tobago located on?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1a98b2f778f1e7083602617b5ffd9d19</td>\n",
       "      <td>what continent is trinidad and tobago located at?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>0b52591a8b92d86074362ae6dccf03ee</td>\n",
       "      <td>zac efron character in high school musical?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>132376b752a28c18ef8d6c9f5815062c</td>\n",
       "      <td>who does zac efron portrait in high school musical?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>c43f6a545cdbf4bf808b81635a974cca</td>\n",
       "      <td>who does the actor zac efron play in high school musical?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>d64e5d361918182067caedda71033c63</td>\n",
       "      <td>who played the role of jake ryan on hannah montana?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cody linley'], 'NormalizedAliases': ['cody linley'], 'NormalizedValue': 'cody linley', 'Type': 'FreeForm', 'Value': 'cody ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>2ffeefb4895ae2db7b48ebffd031cc2e</td>\n",
       "      <td>who plays jake ryan in hannaha montaina?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['cody linley'], 'NormalizedAliases': ['cody linley'], 'NormalizedValue': 'cody linley', 'Type': 'FreeForm', 'Value': 'cody ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>b04793d90092d28b956daaee219a55f5</td>\n",
       "      <td>who appointed the first us chief justice in 1789?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['john jay'], 'NormalizedAliases': ['john jay'], 'NormalizedValue': 'john jay', 'Type': 'FreeForm', 'Value': 'john jay'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>92f2062f50c7ee7bbdc42c7111ded0f4</td>\n",
       "      <td>who became the first chief justice for the us in 1789?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['john jay'], 'NormalizedAliases': ['john jay'], 'NormalizedValue': 'john jay', 'Type': 'FreeForm', 'Value': 'john jay'}</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>ea93dd521ccc346f3c33c22eaad63ec0</td>\n",
       "      <td>when james bowie died?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>b367c2c7cc8977c59e866f7f805c069b</td>\n",
       "      <td>what day did james bowie die?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>8d3df4a037ce5b44f50d0bf7f8cca9f1</td>\n",
       "      <td>when did james bowie die in?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>e161876a9bea7c1bd33c25a5106ef26c</td>\n",
       "      <td>what is the height of mount everest?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>e25e1129126d279590c6389c294a0814</td>\n",
       "      <td>height of mt everest?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>111e3e9d5feeb88edea3a8cabb22dce6</td>\n",
       "      <td>height of mount everest?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>a5416357056a3fe9d6b60129253f1bd6</td>\n",
       "      <td>what did thomas jefferson serve under john adams?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['vice president of the united states'], 'NormalizedAliases': ['vice president of the united states'], 'NormalizedValue': 'v...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259</th>\n",
       "      <td>63c02d120c5582a399f16e42b2a7f0a4</td>\n",
       "      <td>what did thomas jefferson serve as for john adams?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['vice president of the united states'], 'NormalizedAliases': ['vice president of the united states'], 'NormalizedValue': 'v...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>98621be50b14f7e32c785ae8731ea821</td>\n",
       "      <td>roberto clemente where did he die?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>7ec5a537decf4bcd49b01813b855594b</td>\n",
       "      <td>where did roberto clemente die in the plane crash?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>d94dbe8bf582f3ab77f9f2ca9e507eef</td>\n",
       "      <td>where did roberto clemante die?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0759c97efbc1bcaa1e1b0e2512fc8d68</td>\n",
       "      <td>who does michael myers hate?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['laurie strode'], 'NormalizedAliases': ['laurie strode'], 'NormalizedValue': 'laurie strode', 'Type': 'FreeForm', 'Value': ...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>7bf3c05e9a62e7b7ae9e2102cebf2a57</td>\n",
       "      <td>what is a hogan's heroes group?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['hogan's heroes'], 'NormalizedAliases': ['hogan 's heroes'], 'NormalizedValue': 'hogan 's heroes', 'Type': 'FreeForm', 'Val...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1cd342fa4246344c2ef9d5213e53bbaa</td>\n",
       "      <td>where did barbara jordan go to elementary school?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['roberson elementary school'], 'NormalizedAliases': ['roberson elementary school'], 'NormalizedValue': 'roberson elementary...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>95fde0589fbb3c44ea14f060fc01a1f9</td>\n",
       "      <td>what was amitabh bachchan's first movie?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>5d4d9198791b97ea035e0ccaa02fbe21</td>\n",
       "      <td>which is the 1st film of bachchan?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>1d1abf1f13db32d161c411c40d536438</td>\n",
       "      <td>which was amitabh bachchan's first movie?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>8d88f03efd626a677f0a755a26537bdf</td>\n",
       "      <td>what is the name of the city and state where woodstock was held?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>1ba657b2f8f3b5d10921e250c1118317</td>\n",
       "      <td>what city and state did woodstock concert first appear?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>06ffd2c34d211592d5a1a8c5f4a38779</td>\n",
       "      <td>in what city and state did the popular woodstock concert occur?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>1dd8dda4cd0bc714049a24076c934baf</td>\n",
       "      <td>when is antonia johnson carter birthday?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1983-10-26'], 'NormalizedAliases': ['1983-10-26'], 'NormalizedValue': '1983-10-26', 'Type': 'FreeForm', 'Value': '1983-10-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>361d6e84a6383465aa91385ae42ba2f5</td>\n",
       "      <td>when is antonia toya carter's birthday?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['1983-10-26'], 'NormalizedAliases': ['1983-10-26'], 'NormalizedValue': '1983-10-26', 'Type': 'FreeForm', 'Value': '1983-10-...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>c81d03cd1e2f4d8cdb10cc79f324b4c1</td>\n",
       "      <td>who was the prime minister of britain during its battle with germany?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'Aliases': ['neville chamberlain'], 'NormalizedAliases': ['neville chamberlain'], 'NormalizedValue': 'neville chamberlain', 'Type': 'Fr...</td>\n",
       "      <td>ComQA_Googled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6275 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            QuestionId                                                                    Question SearchResults EntityPages QuestionSource                                                                                                                                       Answer        dataset\n",
       "0     3cac9c75821103eef095a4c3a5d8df11                             who does the voice of carl in phineas and ferb?            []          []                 {'Aliases': ['tyler alexander mann'], 'NormalizedAliases': ['tyler alexander mann'], 'NormalizedValue': 'tyler alexander mann', 'Type': ...  ComQA_Googled\n",
       "1     b414d23c35cfe20dd6dc425959fc3f83                               who is the voice of carl in phineas and ferb?            []          []                 {'Aliases': ['tyler alexander mann'], 'NormalizedAliases': ['tyler alexander mann'], 'NormalizedValue': 'tyler alexander mann', 'Type': ...  ComQA_Googled\n",
       "2     cacf77ba23eab9597e71497c7bf38b02                                        the first black president of mexico?            []          []                 {'Aliases': ['vicente guerrero'], 'NormalizedAliases': ['vicente guerrero'], 'NormalizedValue': 'vicente guerrero', 'Type': 'FreeForm', ...  ComQA_Googled\n",
       "3     544312c8d0a375647434a3ad28d908c4                                   who is queens elizabeth's the 2nd mother?            []          []                 {'Aliases': ['queen elizabeth the queen mother'], 'NormalizedAliases': ['queen elizabeth the queen mother'], 'NormalizedValue': 'queen e...  ComQA_Googled\n",
       "4     efd8744ce9833eea1dadcc3478ffd0ef                           who plays james potter in the harry potter films?            []          []                 {'Aliases': ['robbie jarvis'], 'NormalizedAliases': ['robbie jarvis'], 'NormalizedValue': 'robbie jarvis', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "5     617d233b6ada1f7762b66c098772e4fa                                who is james potter the harry potter father?            []          []                 {'Aliases': ['robbie jarvis'], 'NormalizedAliases': ['robbie jarvis'], 'NormalizedValue': 'robbie jarvis', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "6     8d708a6eabb7cc66ba7bc4d5eb68ac61                                     where was the ed sullivan show located?            []          []                 {'Aliases': ['ed sullivan theater'], 'NormalizedAliases': ['ed sullivan theater'], 'NormalizedValue': 'ed sullivan theater', 'Type': 'Fr...  ComQA_Googled\n",
       "7     14584b3ec3743217779b1f0816f3b231                           hitler became chancellor of germany in what year?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "8     e071afe9a67e3b6ca98172c8072afb68                          what year did hitler become chancellor of germany?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "9     a0b5787c102df440290f0234a916e91a                     what year was hitler elected the chancellor of germany?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "10    b16ceaf42a41e8118b8b5a2aecc3487c                  in which year did hitler become the chancellor of germany?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "11    ffed58a80204fe8ccfdbd75d1e2ac98c                   what year did adolf hitler become chancellor for germany?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "12    92ded5a964c6e87640da3dca40b00430                         which date did hitler become chancellor of germany?            []          []                 {'Aliases': ['1933-01-30'], 'NormalizedAliases': ['1933-01-30'], 'NormalizedValue': '1933-01-30', 'Type': 'FreeForm', 'Value': '1933-01-...  ComQA_Googled\n",
       "13    3e8ddd2672d996dbbf2759ab4f93139f                                what was rick riordan's first book he wrote?            []          []                 {'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "14    5cb7df0fdbfb4d83d68cbeda6bb487b7                                 what was rick riordan's first book written?            []          []                 {'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "15    6af6dac495f74f8786549579bf2e59a4                                 what was the first book rick riordan wrote?            []          []                 {'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "16    2dac89a36c4dc164490ac342b3b4bca6                                      what is rick riordans first kids book?            []          []                 {'Aliases': ['big red tequila'], 'NormalizedAliases': ['big red tequila'], 'NormalizedValue': 'big red tequila', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "17    af59c329333783861a64c0e51ba6e890                                        when was remember the titans filmed?            []          []                                        {'Aliases': ['2000'], 'NormalizedAliases': ['2000'], 'NormalizedValue': '2000', 'Type': 'FreeForm', 'Value': '2000'}  ComQA_Googled\n",
       "18    f725f241f3b29809ada8225a20648e32                              when was the movie remember the titans filmed?            []          []                                        {'Aliases': ['2000'], 'NormalizedAliases': ['2000'], 'NormalizedValue': '2000', 'Type': 'FreeForm', 'Value': '2000'}  ComQA_Googled\n",
       "19    dfef6760c16e010d43dc017dc81b67cc                                  largest city located along the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "20    0b2c7b7591bcefffd4c4802ca2d609ba              what largest city in africa is on the banks of the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "21    4823b21d6fea864406e56d4bac813b69                                             largest city on the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "22    598bdf7a5ed63160074c2ffb6107c34c                                             largest city by the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "23    63b73b10883c9dbda112b9789bb2d908                             largest city in africa built on the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "24    846db2e66d0c26c9c72e33747e7798e3  what is the largest city in africa that is on the banks of the nile river?            []          []                                    {'Aliases': ['cairo'], 'NormalizedAliases': ['cairo'], 'NormalizedValue': 'cairo', 'Type': 'FreeForm', 'Value': 'cairo'}  ComQA_Googled\n",
       "25    50ead345b027a8bc72c51838af603d33                                     how many us presidents have there been?            []          []                                                {'Aliases': ['44'], 'NormalizedAliases': ['44'], 'NormalizedValue': '44', 'Type': 'FreeForm', 'Value': '44'}  ComQA_Googled\n",
       "26    800f535cc14908a8dea2911f6e11d815                                        where is trinidad an tobago located?            []          []                 {'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "27    39202a3b3c243beefa2c401532b3dd6f                           on what continent is tobago and trinidad located?            []          []                 {'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "28    cc9948d61187ec0b9febe3918c254882                                    where is trinidad and tobago located on?            []          []                 {'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "29    1a98b2f778f1e7083602617b5ffd9d19                           what continent is trinidad and tobago located at?            []          []                 {'Aliases': ['south america'], 'NormalizedAliases': ['south america'], 'NormalizedValue': 'south america', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "...                                ...                                                                         ...           ...         ...            ...                                                                                                                                          ...            ...\n",
       "6245  0b52591a8b92d86074362ae6dccf03ee                                 zac efron character in high school musical?            []          []                 {'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...  ComQA_Googled\n",
       "6246  132376b752a28c18ef8d6c9f5815062c                         who does zac efron portrait in high school musical?            []          []                 {'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...  ComQA_Googled\n",
       "6247  c43f6a545cdbf4bf808b81635a974cca                   who does the actor zac efron play in high school musical?            []          []                 {'Aliases': ['troy bolton'], 'NormalizedAliases': ['troy bolton'], 'NormalizedValue': 'troy bolton', 'Type': 'FreeForm', 'Value': 'troy ...  ComQA_Googled\n",
       "6248  d64e5d361918182067caedda71033c63                         who played the role of jake ryan on hannah montana?            []          []                 {'Aliases': ['cody linley'], 'NormalizedAliases': ['cody linley'], 'NormalizedValue': 'cody linley', 'Type': 'FreeForm', 'Value': 'cody ...  ComQA_Googled\n",
       "6249  2ffeefb4895ae2db7b48ebffd031cc2e                                    who plays jake ryan in hannaha montaina?            []          []                 {'Aliases': ['cody linley'], 'NormalizedAliases': ['cody linley'], 'NormalizedValue': 'cody linley', 'Type': 'FreeForm', 'Value': 'cody ...  ComQA_Googled\n",
       "6250  b04793d90092d28b956daaee219a55f5                           who appointed the first us chief justice in 1789?            []          []                        {'Aliases': ['john jay'], 'NormalizedAliases': ['john jay'], 'NormalizedValue': 'john jay', 'Type': 'FreeForm', 'Value': 'john jay'}  ComQA_Googled\n",
       "6251  92f2062f50c7ee7bbdc42c7111ded0f4                      who became the first chief justice for the us in 1789?            []          []                        {'Aliases': ['john jay'], 'NormalizedAliases': ['john jay'], 'NormalizedValue': 'john jay', 'Type': 'FreeForm', 'Value': 'john jay'}  ComQA_Googled\n",
       "6252  ea93dd521ccc346f3c33c22eaad63ec0                                                      when james bowie died?            []          []                 {'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...  ComQA_Googled\n",
       "6253  b367c2c7cc8977c59e866f7f805c069b                                               what day did james bowie die?            []          []                 {'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...  ComQA_Googled\n",
       "6254  8d3df4a037ce5b44f50d0bf7f8cca9f1                                                when did james bowie die in?            []          []                 {'Aliases': ['1836-03-06'], 'NormalizedAliases': ['1836-03-06'], 'NormalizedValue': '1836-03-06', 'Type': 'FreeForm', 'Value': '1836-03-...  ComQA_Googled\n",
       "6255  e161876a9bea7c1bd33c25a5106ef26c                                        what is the height of mount everest?            []          []                 {'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...  ComQA_Googled\n",
       "6256  e25e1129126d279590c6389c294a0814                                                       height of mt everest?            []          []                 {'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...  ComQA_Googled\n",
       "6257  111e3e9d5feeb88edea3a8cabb22dce6                                                    height of mount everest?            []          []                 {'Aliases': ['8,848 meter'], 'NormalizedAliases': ['8,848 meter'], 'NormalizedValue': '8,848 meter', 'Type': 'FreeForm', 'Value': '8,848...  ComQA_Googled\n",
       "6258  a5416357056a3fe9d6b60129253f1bd6                           what did thomas jefferson serve under john adams?            []          []                 {'Aliases': ['vice president of the united states'], 'NormalizedAliases': ['vice president of the united states'], 'NormalizedValue': 'v...  ComQA_Googled\n",
       "6259  63c02d120c5582a399f16e42b2a7f0a4                          what did thomas jefferson serve as for john adams?            []          []                 {'Aliases': ['vice president of the united states'], 'NormalizedAliases': ['vice president of the united states'], 'NormalizedValue': 'v...  ComQA_Googled\n",
       "6260  98621be50b14f7e32c785ae8731ea821                                          roberto clemente where did he die?            []          []                 {'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...  ComQA_Googled\n",
       "6261  7ec5a537decf4bcd49b01813b855594b                          where did roberto clemente die in the plane crash?            []          []                 {'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...  ComQA_Googled\n",
       "6262  d94dbe8bf582f3ab77f9f2ca9e507eef                                             where did roberto clemante die?            []          []                 {'Aliases': ['san juan, puerto rico'], 'NormalizedAliases': ['san juan , puerto rico'], 'NormalizedValue': 'san juan , puerto rico', 'Ty...  ComQA_Googled\n",
       "6263  0759c97efbc1bcaa1e1b0e2512fc8d68                                                who does michael myers hate?            []          []                 {'Aliases': ['laurie strode'], 'NormalizedAliases': ['laurie strode'], 'NormalizedValue': 'laurie strode', 'Type': 'FreeForm', 'Value': ...  ComQA_Googled\n",
       "6264  7bf3c05e9a62e7b7ae9e2102cebf2a57                                             what is a hogan's heroes group?            []          []                 {'Aliases': ['hogan's heroes'], 'NormalizedAliases': ['hogan 's heroes'], 'NormalizedValue': 'hogan 's heroes', 'Type': 'FreeForm', 'Val...  ComQA_Googled\n",
       "6265  1cd342fa4246344c2ef9d5213e53bbaa                           where did barbara jordan go to elementary school?            []          []                 {'Aliases': ['roberson elementary school'], 'NormalizedAliases': ['roberson elementary school'], 'NormalizedValue': 'roberson elementary...  ComQA_Googled\n",
       "6266  95fde0589fbb3c44ea14f060fc01a1f9                                    what was amitabh bachchan's first movie?            []          []                 {'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "6267  5d4d9198791b97ea035e0ccaa02fbe21                                          which is the 1st film of bachchan?            []          []                 {'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "6268  1d1abf1f13db32d161c411c40d536438                                   which was amitabh bachchan's first movie?            []          []                 {'Aliases': ['saat hindustani'], 'NormalizedAliases': ['saat hindustani'], 'NormalizedValue': 'saat hindustani', 'Type': 'FreeForm', 'Va...  ComQA_Googled\n",
       "6269  8d88f03efd626a677f0a755a26537bdf            what is the name of the city and state where woodstock was held?            []          []                 {'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...  ComQA_Googled\n",
       "6270  1ba657b2f8f3b5d10921e250c1118317                     what city and state did woodstock concert first appear?            []          []                 {'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...  ComQA_Googled\n",
       "6271  06ffd2c34d211592d5a1a8c5f4a38779             in what city and state did the popular woodstock concert occur?            []          []                 {'Aliases': ['woodstock, new york'], 'NormalizedAliases': ['woodstock , new york'], 'NormalizedValue': 'woodstock , new york', 'Type': '...  ComQA_Googled\n",
       "6272  1dd8dda4cd0bc714049a24076c934baf                                    when is antonia johnson carter birthday?            []          []                 {'Aliases': ['1983-10-26'], 'NormalizedAliases': ['1983-10-26'], 'NormalizedValue': '1983-10-26', 'Type': 'FreeForm', 'Value': '1983-10-...  ComQA_Googled\n",
       "6273  361d6e84a6383465aa91385ae42ba2f5                                     when is antonia toya carter's birthday?            []          []                 {'Aliases': ['1983-10-26'], 'NormalizedAliases': ['1983-10-26'], 'NormalizedValue': '1983-10-26', 'Type': 'FreeForm', 'Value': '1983-10-...  ComQA_Googled\n",
       "6274  c81d03cd1e2f4d8cdb10cc79f324b4c1       who was the prime minister of britain during its battle with germany?            []          []                 {'Aliases': ['neville chamberlain'], 'NormalizedAliases': ['neville chamberlain'], 'NormalizedValue': 'neville chamberlain', 'Type': 'Fr...  ComQA_Googled\n",
       "\n",
       "[6275 rows x 7 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_triviaqa_format[questions_triviaqa_format['SearchResults'].apply(len)==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:54:10.417162Z",
     "start_time": "2018-05-31T15:54:10.414441Z"
    }
   },
   "source": [
    "# Building Evidence Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.280518Z",
     "start_time": "2018-10-07T09:34:40.277768Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print('checking if there exist cases in which there are no answers?')\n",
    "#print(len(questions_triviaqa_format[questions_triviaqa_format['Answer'].agg(lambda x: x['Value']).apply(len)==0]['Answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.286869Z",
     "start_time": "2018-10-07T09:34:40.282230Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "triviaqa_dict = {}\n",
    "triviaqa_dict['Data'] = questions_triviaqa_format\n",
    "triviaqa_dict['Domain'] = 'unfiltered-web'\n",
    "triviaqa_dict['Split'] = EVAL_SET\n",
    "triviaqa_dict['VerifiedEval'] = False\n",
    "triviaqa_dict['Version'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.301704Z",
     "start_time": "2018-10-07T09:34:40.289041Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "data_df = triviaqa_dict['Data']\n",
    "data_df = data_df.set_index('QuestionId')\n",
    "org_data_df = data_df.copy(deep=True)\n",
    "data_df = data_df.rename(columns = {'SearchResults':'OrgSearchResults'})\n",
    "data_df['SearchResults'] = None\n",
    "data_df = data_df[data_df['OrgSearchResults'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build googled evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.396648Z",
     "start_time": "2018-10-07T09:34:40.303812Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OLD create a query to file map\n",
    "if False and not USE_SQUAD_ORG_CONTEXT and not USE_MSMARCO_ORG_CONTEXT:\n",
    "    if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR + 'evidence/'):\n",
    "        os.mkdir(EVIDENCE_DIR + 'evidence/')\n",
    "\n",
    "    if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR +'evidence/' + EXP_NAME):\n",
    "        os.mkdir(EVIDENCE_DIR + 'evidence/' + EXP_NAME)\n",
    "\n",
    "    train_file_ind = int(0)\n",
    "    for i in tqdm(range(len(data_df)), total=len(data_df), ncols=80, desc=\"building evidence files\"):\n",
    "        question = data_df.iloc[i]\n",
    "        questionID = data_df.index[i]\n",
    "        # building 10 text files out of 100 snippets\n",
    "        SearchResults = []\n",
    "        files = []\n",
    "        filenames = []\n",
    "        file_ind = 0\n",
    "        google_results = question['OrgSearchResults']\n",
    "        train_file_ind += 1\n",
    "\n",
    "\n",
    "        if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR + 'evidence/' + EXP_NAME + '/' + str(int(train_file_ind / 100))):\n",
    "            os.mkdir(EVIDENCE_DIR + 'evidence/' + EXP_NAME + '/' + str(int(train_file_ind / 100)))\n",
    "            #if train_file_ind % 1000 == 0:\n",
    "            #    print(EVIDENCE_DIR + 'evidence/' + EXP_NAME + '/' + str(int(train_file_ind / 100)))\n",
    "\n",
    "        # go over all google snippets (usually 100)\n",
    "        for ind, g in enumerate(google_results):\n",
    "            file_ind = file_ind % FILES_PER_QUESTION\n",
    "            if len(files) <= file_ind:\n",
    "                file_name = EXP_NAME + '/' + str(int(train_file_ind / 100)) + \"/\" + \\\n",
    "                    questionID + '_' + str(file_ind) + '.txt'\n",
    "                #SearchResults.append({'Rank':ind, 'Description':g['snippet'],'Title':g['title'],'DisplayUrl':g['url'] , \\\n",
    "                #              'Url':g['url'] + file_name.replace('/','_').replace('.txt',''),'Filename':file_name })\n",
    "                # Moving to empty evidence text ( it will be taken from the files)\n",
    "                SearchResults.append({'Rank':ind, 'Description':'','Title':'','DisplayUrl':'' , \\\n",
    "                              'Url':g['url'] + file_name.replace('/','_').replace('.txt',''),'Filename':file_name })\n",
    "                \n",
    "                files.append('')\n",
    "                filenames.append(file_name)\n",
    "\n",
    "            files[file_ind] += str(\n",
    "                ind) + '. ' + g['title'] + '\\n' + g['snippet'] + '\\n'\n",
    "\n",
    "            file_ind += 1\n",
    "\n",
    "        # saving files\n",
    "        if WRITE_EVIDENCE:\n",
    "            for file_str, file_name in zip(files, filenames):\n",
    "                with open(EVIDENCE_DIR + 'evidence/' + file_name, 'w') as outfile:\n",
    "                    outfile.write(file_str)\n",
    "\n",
    "        data_df.at[questionID, 'SearchResults'] = SearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.404567Z",
     "start_time": "2018-10-07T09:34:40.398257Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# check folder name distribution (200 folders per dataset)\n",
    "if False:\n",
    "    x = []\n",
    "    for ind in list(data_df.index):\n",
    "        m = hashlib.md5()\n",
    "        m.update(ind.encode())\n",
    "        questionID_hex = m.hexdigest()\n",
    "        x.append(sum(questionID_hex.encode()) % 200)\n",
    "    pd.Series(x).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:40.616839Z",
     "start_time": "2018-10-07T09:34:40.406280Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# write_evidence\n",
    "def write_evidence(data_df,EVIDENCE_DIR):\n",
    "    if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR + 'multiqa_evidence/'):\n",
    "        os.mkdir(EVIDENCE_DIR + 'multiqa_evidence/')\n",
    "\n",
    "    all_search_results = []\n",
    "    train_file_ind = int(0)\n",
    "    for i in tqdm(range(len(data_df)), total=len(data_df), ncols=80, desc=\"building evidence files\"):\n",
    "    #for i in tqdm(range(1), total=1, ncols=80, desc=\"building evidence files\"):\n",
    "        question = data_df.iloc[i]\n",
    "        questionID = data_df.index[i]\n",
    "        questionID = questionID.replace('/','_')\n",
    "        # building 10 text files out of 100 snippets\n",
    "        SearchResults = []\n",
    "        files = []\n",
    "        filenames = []\n",
    "        file_ind = 0\n",
    "        google_results = question['OrgSearchResults']\n",
    "        train_file_ind += 1\n",
    "\n",
    "        # creating a unique question identifier\n",
    "        m = hashlib.md5()\n",
    "        if type(questionID) != str:\n",
    "            questionID = str(questionID)\n",
    "        m.update(questionID.encode())\n",
    "        questionID_hex = m.hexdigest()\n",
    "        folder_ind = str(sum(questionID_hex.encode()) % 200)\n",
    "\n",
    "        if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR + 'multiqa_evidence/' + question['dataset'] ):\n",
    "            os.mkdir(EVIDENCE_DIR + 'multiqa_evidence/' + question['dataset'] )\n",
    "\n",
    "        if WRITE_EVIDENCE and not os.path.isdir(EVIDENCE_DIR + 'multiqa_evidence/' + question['dataset'] + '/' + folder_ind):\n",
    "            os.mkdir(EVIDENCE_DIR + 'multiqa_evidence/' + question['dataset'] + '/' + folder_ind)\n",
    "            #if train_file_ind % 1000 == 0:\n",
    "            #    print(EVIDENCE_DIR + 'evidence/' + EXP_NAME + '/' + str(int(train_file_ind / 100)))\n",
    "\n",
    "        # go over all google snippets (usually 100)\n",
    "        if WRITE_EVIDENCE:\n",
    "            for ind, g in enumerate(google_results):\n",
    "                file_ind = file_ind % FILES_PER_QUESTION\n",
    "                if len(files) <= file_ind:\n",
    "                    file_name = question['dataset'] + '/' + folder_ind + \"/\" + \\\n",
    "                        questionID + '_' + str(file_ind) + '.txt'\n",
    "                    # Moving to empty evidence text ( it will be taken from the files)\n",
    "                    SearchResults.append({'Rank':ind, 'Description':'','Title':'','DisplayUrl':'' , \\\n",
    "                                  'Url':question['dataset'] + '_' + file_name.replace('/','_').replace('.txt',''), \\\n",
    "                                          'Filename':file_name })\n",
    "\n",
    "                    files.append('')\n",
    "                    filenames.append(file_name)\n",
    "\n",
    "                if WRITE_EVIDENCE:\n",
    "                    if len(google_results)>1:\n",
    "                        files[file_ind] += str(ind) + '. ' + g['title'] + '\\n' + g['snippet'] + '\\n'\n",
    "                    else:\n",
    "                        # this coveres cases with only one search result, or original context like squad\n",
    "                        if len(g['title'])>0:\n",
    "                            files[file_ind] += g['title'] + '\\n' + g['snippet'] + '\\n'\n",
    "                        else:\n",
    "                            files[file_ind] += g['snippet'] \n",
    "\n",
    "                file_ind += 1\n",
    "        else:\n",
    "            for file_ind in range(FILES_PER_QUESTION):\n",
    "                file_name = question['dataset'] + '/' + folder_ind + \"/\" + \\\n",
    "                    questionID + '_' + str(file_ind) + '.txt'\n",
    "                if os.path.exists(EVIDENCE_DIR + 'multiqa_evidence/' + file_name):\n",
    "                    # Moving to empty evidence text ( it will be taken from the files)\n",
    "                    SearchResults.append({'Rank':file_ind, 'Description':'','Title':'','DisplayUrl':'' , \\\n",
    "                                  'Url':question['dataset'] + '_' + file_name.replace('/','_').replace('.txt',''), \\\n",
    "                                          'Filename':file_name })\n",
    "                else:\n",
    "                    #print(EVIDENCE_DIR + 'multiqa_evidence/' + file_name)\n",
    "                    break\n",
    "\n",
    "        # saving files\n",
    "        if WRITE_EVIDENCE:\n",
    "            for file_str, file_name in zip(files, filenames):\n",
    "                with open(EVIDENCE_DIR + 'multiqa_evidence/' + file_name, 'w') as outfile:\n",
    "                    outfile.write(file_str)\n",
    "\n",
    "        all_search_results.append(SearchResults)            \n",
    "    \n",
    "    data_df['SearchResults'] = all_search_results\n",
    "        \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.615743Z",
     "start_time": "2018-10-07T09:34:40.618608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building evidence files: 100%|████████████| 6275/6275 [00:03<00:00, 1576.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#%lprun -f write_evidence write_evidence(data_df,EVIDENCE_DIR)\n",
    "if not USE_TRIVIAQA and not USE_TRIVIAQA_ORG_CONTEXT:\n",
    "    data_df = write_evidence(data_df,EVIDENCE_DIR)\n",
    "else:\n",
    "    all_search_results= [ ]\n",
    "    for i in tqdm(range(len(data_df)), total=len(data_df), ncols=80, desc=\"building evidence files\"):\n",
    "        question = data_df.iloc[i]\n",
    "        google_results = question['OrgSearchResults']\n",
    "        question = data_df.iloc[i]\n",
    "        SearchResults = []\n",
    "        for ind, g in enumerate(google_results):\n",
    "            new_g = g.copy()\n",
    "            new_g['Filename'] = question['dataset'] + '/' + g['Filename']\n",
    "            SearchResults.append(new_g)\n",
    "        all_search_results.append(SearchResults)\n",
    "    data_df['SearchResults'] = all_search_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.622638Z",
     "start_time": "2018-10-07T09:34:44.617489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df[data_df['SearchResults'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:33:42.310094Z",
     "start_time": "2018-05-15T07:33:42.279265Z"
    }
   },
   "source": [
    "# Calc answer in google percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.676204Z",
     "start_time": "2018-10-07T09:34:44.624491Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "INSPECT_EVIDENCE = False\n",
    "if CALC_ANSWER_IN_GOOGLE_PERC:\n",
    "    answer_found_mat = np.zeros((len(data_df),100))\n",
    "    q_ind = 0\n",
    "    for ind,question in tqdm(data_df.iterrows(),total=len(data_df), ncols=80, \\\n",
    "                             desc='checking how many gold answer are within question snippets'):\n",
    "        normalized_aliases = question['Answer']['NormalizedAliases']\n",
    "\n",
    "        for s_ind,result in enumerate(question['SearchResults']):\n",
    "            for alias in normalized_aliases:\n",
    "                \n",
    "                with open(EVIDENCE_DIR + 'multiqa_evidence/' + result['Filename'], 'r') as outfile:\n",
    "                    result_text = outfile.read()\n",
    "                #result_text = result['Title'] + ' ' + result['Description']\n",
    "                p = re.compile(r'\\b({0})\\b'.format(re.escape(alias)), re.IGNORECASE)\n",
    "                res = re.findall(p, result_text)\n",
    "                #if result_text.find(alias)>-1:\n",
    "                 #   answer_found_mat[q_ind , s_ind] = 1\n",
    "                if len(res) > 0:\n",
    "                    if INSPECT_EVIDENCE:\n",
    "                        print('-------------')\n",
    "                        print('Question  ' + question['Question'])\n",
    "                        print('Answer:  ' + alias)\n",
    "                        print('Context:')\n",
    "                        print(result_text) \n",
    "                    answer_found_mat[q_ind , s_ind] = 1\n",
    "                    break\n",
    "        q_ind += 1\n",
    "        \n",
    "        if INSPECT_EVIDENCE and q_ind > 10:\n",
    "            break\n",
    "                #else:\n",
    "                #    print(alias + ' --- ' + result_text)\n",
    "    \n",
    "    print('answer are within question snippets {0}%'.format(100.0* (answer_found_mat.sum(axis=1)>0).sum() / len(data_df)))\n",
    "    print('number of examples with answer are within question snippets {0}'.format((answer_found_mat.sum(axis=1)>0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sanity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.687953Z",
     "start_time": "2018-10-07T09:34:44.678964Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question            0\n",
       "OrgSearchResults    0\n",
       "EntityPages         0\n",
       "QuestionSource      0\n",
       "Answer              0\n",
       "dataset             0\n",
       "SearchResults       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional sanity tests\n",
    "(data_df.isnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.695697Z",
     "start_time": "2018-10-07T09:34:44.689616Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# additional sanity tests\n",
    "if data_df['SearchResults'].isnull().sum()==0:\n",
    "    data_df['SearchResults'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.706162Z",
     "start_time": "2018-10-07T09:34:44.697885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.92720970537262"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['SearchResults'].apply(len) == 0]['Question'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:44.719393Z",
     "start_time": "2018-10-07T09:34:44.708239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.31224370240187"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['SearchResults'].apply(len) > 0]['Question'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:45.875752Z",
     "start_time": "2018-10-07T09:34:44.721784Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking if filenames exist: 100%|████████| 6275/6275 [00:01<00:00, 5536.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found : 102400\n",
      "not_found : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if True:#WRITE_EVIDENCE:\n",
    "    found = 0\n",
    "    not_found = 0\n",
    "    for i in tqdm(range(len(data_df)), total=len(data_df), ncols=80, desc=\"checking if filenames exist\"):\n",
    "        question = data_df.iloc[i]\n",
    "        questionID = data_df.index[i]\n",
    "        for ind, g in enumerate(question['SearchResults']):\n",
    "            if os.path.exists(EVIDENCE_DIR + 'multiqa_evidence/' + g['Filename']):\n",
    "                found += 1\n",
    "            else:\n",
    "                print(g['Filename'])\n",
    "                not_found += 1\n",
    "\n",
    "    print('found : {0}'.format(found))\n",
    "    print('not_found : {0}'.format(not_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:45.888192Z",
     "start_time": "2018-10-07T09:34:45.877731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of examples saved: 5121\n"
     ]
    }
   ],
   "source": [
    "del data_df['OrgSearchResults']\n",
    "\n",
    "if EVAL_SET == 'train':\n",
    "    data_df = data_df[data_df['SearchResults'].apply(len)>0]\n",
    "\n",
    "# randomizing the samples:\n",
    "data_df = data_df.sample(frac=1)\n",
    "\n",
    "print('Amount of examples saved: %d' % len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.025768Z",
     "start_time": "2018-10-07T09:34:45.889945Z"
    },
    "code_folding": [
     3
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if not WRITE_EVIDENCE:\n",
    "    if not os.path.isdir('../output/' ):\n",
    "        os.mkdir('../output/' )\n",
    "    if not os.path.isdir('../output/' + EXP_NAME):\n",
    "        os.mkdir('../output/' + EXP_NAME)\n",
    "\n",
    "    if EVAL_SET == 'test':\n",
    "        triviaqa_dict['Data'] = data_df.reset_index().to_dict(orient='rows')\n",
    "        with zipfile.ZipFile('../output/' + EXP_NAME + '/' + \"unfiltered-web-test.json.zip\", \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.writestr('unfiltered-web-test.json', json.dumps(triviaqa_dict, sort_keys=True, indent=4))\n",
    "    if EVAL_SET == 'dev':\n",
    "        triviaqa_dict['Data'] = data_df.reset_index().to_dict(orient='rows')\n",
    "        with zipfile.ZipFile('../output/' + EXP_NAME + '/' + \"unfiltered-web-dev.json.zip\", \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.writestr('unfiltered-web-dev.json', json.dumps(triviaqa_dict, sort_keys=True, indent=4))\n",
    "    if EVAL_SET == 'train':\n",
    "        triviaqa_dict['Data'] = data_df.reset_index().to_dict(orient='rows')\n",
    "        with zipfile.ZipFile('../output/' + EXP_NAME + '/' + \"unfiltered-web-train.json.zip\", \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.writestr('unfiltered-web-train.json', json.dumps(triviaqa_dict, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.031535Z",
     "start_time": "2018-10-07T09:34:48.027688Z"
    }
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    path = '/Users/alontalmor/Documents/dev/datasets/NewsQA/newsqa-data-v1/cnn/stories/13012604e3203c18df09289dfedd14cde67cf40b.story'\n",
    "    with open(path,'r') as f:\n",
    "        x = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.042775Z",
     "start_time": "2018-10-07T09:34:48.033653Z"
    }
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    with zipfile.ZipFile('../output/compwebq_with_triviaqa/unfiltered-web-train.json.zip','r') as myzip:\n",
    "            with myzip.open('unfiltered-web-train.json') as myfile:\n",
    "                questions = json.load(myfile)\n",
    "                compwebq_with_triviaqa = pd.DataFrame(questions['Data'])\n",
    "    compwebq1 = compwebq_with_triviaqa[compwebq_with_triviaqa['QuestionId'].str.startswith('WebQ')]\n",
    "    del compwebq_with_triviaqa\n",
    "    len(compwebq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.053267Z",
     "start_time": "2018-10-07T09:34:48.044608Z"
    }
   },
   "outputs": [],
   "source": [
    "#RUN_EXPERIMENTS = 1\n",
    "if RUN_EXPERIMENTS:\n",
    "    with zipfile.ZipFile('../output/ComplexWebQuestions/unfiltered-web-dev.json.zip','r') as myzip:\n",
    "        with myzip.open('unfiltered-web-dev.json') as myfile:\n",
    "            questions = json.load(myfile)\n",
    "            compwebq_triviaqa_full_dev = pd.DataFrame(questions['Data'])\n",
    "    compwebq2 = compwebq_triviaqa_full_dev[compwebq_triviaqa_full_dev['QuestionId'].str.startswith('WebQ')]\n",
    "    del compwebq_triviaqa_full_dev\n",
    "    print(len(compwebq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.061015Z",
     "start_time": "2018-10-07T09:34:48.055534Z"
    }
   },
   "outputs": [],
   "source": [
    "if RUN_EXPERIMENTS:\n",
    "    x = compwebq2.merge(compwebq1,on='QuestionId',how='inner')\n",
    "    ((x['SearchResults_x'].apply(len) - x['SearchResults_y'].apply(len))!=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Google "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.114405Z",
     "start_time": "2018-10-07T09:34:48.064669Z"
    }
   },
   "outputs": [],
   "source": [
    "#GOOGLE_FILTERED_FILES = True\n",
    "if False:\n",
    "    dataset = 'ComQA'\n",
    "    trial_num = '2'\n",
    "    BATCH_SIZE = 100\n",
    "    \n",
    "    #question_for_google = Data['ComQA'].to_dict(orient='rows')\n",
    "    question_for_google = Data_triviaqa_format['ComQA_Googled']\n",
    "    question_for_google = question_for_google[question_for_google['SearchResults'].apply(len) == 0].to_dict(orient='rows')\n",
    "    \n",
    "\n",
    "    import dropbox\n",
    "    dbx = dropbox.Dropbox('7j6m2s1jYC0AAAAAAAHy69fu0OxDAU3fPbIjjarqr_1zalj8Mvypf8U71BoLT-AD')\n",
    "\n",
    "    print('iterating over files')\n",
    "    offset = 0\n",
    "    while True:\n",
    "        curr_batch_webanswer_question = question_for_google[offset:offset+BATCH_SIZE]\n",
    "        \n",
    "        if len(curr_batch_webanswer_question) == 0:\n",
    "            break\n",
    "        \n",
    "        new_questions = []\n",
    "        for question in curr_batch_webanswer_question: \n",
    "            goog_question = {}\n",
    "            goog_question['goog_query'] = question['Question']\n",
    "            goog_question['QuestionId'] = question['QuestionId']\n",
    "            new_questions.append(goog_question)\n",
    "        \n",
    "        for_goog_dict = {'target_dir': dataset + '/' + EVAL_SET ,'questions': new_questions}\n",
    "\n",
    "        filename = dataset + '-' + EVAL_SET + '-' + str(offset) + '_' + trial_num +  '_for_goog.json'\n",
    "        with zipfile.ZipFile(filename + '.zip', \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.writestr(filename, json.dumps(for_goog_dict, sort_keys=True, indent=4))\n",
    "        \n",
    "        print(filename)\n",
    "        \n",
    "        with open(filename + '.zip', \"rb\") as f:\n",
    "            dbx.files_upload(f.read(), '/google/' + filename + '.zip', mode = dropbox.files.WriteMode.overwrite)\n",
    "\n",
    "        os.remove(filename + '.zip')    \n",
    "        offset += BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.166721Z",
     "start_time": "2018-10-07T09:34:48.116683Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#GOOGLE_FILTERED_FILES = True\n",
    "if GOOGLE_FILTERED_FILES:\n",
    "    dataset = 'SearchQA'\n",
    "    BATCH_SIZE = 200\n",
    "    \n",
    "    question_for_google = Data_triviaqa_format[dataset].to_dict(orient='rows')\n",
    "\n",
    "    import dropbox\n",
    "    dbx = dropbox.Dropbox('7j6m2s1jYC0AAAAAAAHy69fu0OxDAU3fPbIjjarqr_1zalj8Mvypf8U71BoLT-AD')\n",
    "\n",
    "    print('iterating over files')\n",
    "    offset = 0\n",
    "    while True:\n",
    "        curr_batch_webanswer_question = question_for_google[offset:offset+BATCH_SIZE]\n",
    "        \n",
    "        if len(curr_batch_webanswer_question) == 0:\n",
    "            break\n",
    "        \n",
    "        new_questions = []\n",
    "        for question in curr_batch_webanswer_question: \n",
    "            goog_question = {}\n",
    "            goog_question['goog_query'] = question['Question']\n",
    "            goog_question['QuestionId'] = question['QuestionId']\n",
    "            new_questions.append(goog_question)\n",
    "        \n",
    "        for_goog_dict = {'target_dir': dataset + '/' + EVAL_SET ,'questions': new_questions}\n",
    "\n",
    "        filename = dataset + '-' + EVAL_SET + '-' + str(offset) + '_for_goog.json'\n",
    "        with zipfile.ZipFile(filename + '.zip', \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.writestr(filename, json.dumps(for_goog_dict, sort_keys=True, indent=4))\n",
    "        \n",
    "        print(filename)\n",
    "        \n",
    "        with open(filename + '.zip', \"rb\") as f:\n",
    "            dbx.files_upload(f.read(), '/google/' + filename + '.zip', mode = dropbox.files.WriteMode.overwrite)\n",
    "\n",
    "        os.remove(filename + '.zip')    \n",
    "        offset += BATCH_SIZE\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.173878Z",
     "start_time": "2018-10-07T09:34:48.168224Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    DIR = '/Users/alontalmor/Dropbox/Apps/WebKB/google/'\n",
    "    for dirname, dirnames, filenames in os.walk(DIR):\n",
    "        for filename in tqdm(filenames, total=len(filenames), ncols=80, desc='iterating over all googled files'):\n",
    "            if filename.find('processing')>-1:\n",
    "                os.rename(DIR + filename, DIR + filename.replace('processing','for_goog'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google SearchQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.186320Z",
     "start_time": "2018-10-07T09:34:48.176412Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    DIR = '/Users/alontalmor/Documents/dev/datasets/SearchQA/data_json/'\n",
    "    question_for_google = []\n",
    "    for dirname, dirnames, filenames in os.walk(DIR):\n",
    "        for filename in tqdm(filenames, total=len(filenames), ncols=80, desc='iterating over all googled files'):\n",
    "            with open(DIR + filename,'r') as f:\n",
    "                try:\n",
    "                    single_question_dict = json.load(f)\n",
    "                    question_for_google.append({'Question':single_question_dict['question'], \\\n",
    "                                                'QuestionId':single_question_dict['id']})\n",
    "                except:\n",
    "                    print('bad json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.193320Z",
     "start_time": "2018-10-07T09:34:48.188896Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    Data_triviaqa_format = {}\n",
    "    dataset = 'SearchQA'\n",
    "    Data_triviaqa_format[dataset] = pd.DataFrame(question_for_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.201619Z",
     "start_time": "2018-10-07T09:34:48.195241Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('../output/TriviaQA-Submission/question-output.json','r') as f:\n",
    "        data = json.load(f)\n",
    "        x = pd.Series(data)\n",
    "        x.index = x.index.str.replace('TriviaQA_Org/','')\n",
    "    with zipfile.ZipFile(\"../output/TriviaQA-Submission/submission.zip\", \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
    "        zip_file.writestr('predictions.json', json.dumps(x.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T09:34:48.209566Z",
     "start_time": "2018-10-07T09:34:48.203607Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('/Users/alontalmor/Documents/dev/datasets/HotpotQA/hotpot_train_v1.json','r') as f:\n",
    "        data = json.load(f)\n",
    "        x = pd.DataFrame(data)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "908px",
    "left": "0px",
    "right": "1587.01px",
    "top": "109px",
    "width": "325px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
